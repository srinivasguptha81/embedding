{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# ğŸ” Project 8: Semantic Search & Recommendation System\n",
    "### Lovely Professional University â€” Python & Full Stack Development\n",
    "\n",
    "**Pipeline:** BBC News Dataset â†’ Preprocessing â†’ Word2Vec Embeddings â†’ Semantic Search + Recommendations â†’ PCA/t-SNE Visualization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Install required libraries\n",
    "!pip install gensim scikit-learn matplotlib seaborn pandas numpy kaggle --quiet\n",
    "print(\"âœ… All libraries installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_data",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Module 1: Data Collection & Preprocessing\n",
    "We use the **BBC News Classification Dataset** from Kaggle â€” 2,225 real English news articles across 5 categories: *tech, business, sport, entertainment, politics*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load BBC News dataset from the Kaggle folder structure\n",
    "#\n",
    "# HOW TO GET THE DATASET:\n",
    "#   1. Go to: https://www.kaggle.com/datasets/shivamkushwaha/bbc-full-text-document-classification\n",
    "#   2. Click Download â†’ extract the zip\n",
    "#   3. You will get a folder like: bbc-fulltext (document classification)/\n",
    "#      Inside it: business/, tech/, sport/, entertainment/, politics/\n",
    "#      Each subfolder has 001.txt, 002.txt, ... etc.\n",
    "#   4. Place that top-level folder next to this notebook and set BBC_ROOT below.\n",
    "#\n",
    "# FOLDER STRUCTURE EXPECTED:\n",
    "#   BBC_ROOT/\n",
    "#     â”œâ”€â”€ business/  001.txt  002.txt ...\n",
    "#     â”œâ”€â”€ tech/      001.txt  002.txt ...\n",
    "#     â”œâ”€â”€ sport/     001.txt  002.txt ...\n",
    "#     â”œâ”€â”€ entertainment/ ...\n",
    "#     â””â”€â”€ politics/  ...\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# â”€â”€ SET THIS to your extracted folder path â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "BBC_ROOT = \"bbc-fulltext (document classification)\"   # <-- change if needed\n",
    "# e.g. BBC_ROOT = \"archive/bbc-fulltext (document c...\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def load_bbc_folder(root_path):\n",
    "    \"\"\"Walk category subfolders and read every .txt file into a DataFrame.\"\"\"\n",
    "    records = []\n",
    "    if not os.path.exists(root_path):\n",
    "        return None\n",
    "    for category in sorted(os.listdir(root_path)):\n",
    "        cat_path = os.path.join(root_path, category)\n",
    "        if not os.path.isdir(cat_path):\n",
    "            continue\n",
    "        for txt_file in sorted(glob.glob(os.path.join(cat_path, \"*.txt\"))):\n",
    "            try:\n",
    "                with open(txt_file, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "                    text = f.read().strip().replace(\"\\n\", \" \")\n",
    "                if text:  # skip empty files\n",
    "                    records.append({\"category\": category, \"text\": text})\n",
    "            except Exception as e:\n",
    "                print(f\"  âš ï¸  Skipping {txt_file}: {e}\")\n",
    "    return pd.DataFrame(records) if records else None\n",
    "\n",
    "\n",
    "df = load_bbc_folder(BBC_ROOT)\n",
    "\n",
    "if df is not None and len(df) > 0:\n",
    "    print(f\"âœ… Loaded BBC full-text dataset from folder: {df.shape[0]} articles\")\n",
    "    print(df[\"category\"].value_counts())\n",
    "else:\n",
    "    print(\"âš ï¸  Folder not found or empty. Using built-in 100-article sample.\")\n",
    "    print(f\"   Set BBC_ROOT to the path of your extracted Kaggle download.\")\n",
    "    print(f\"   Current BBC_ROOT = '{BBC_ROOT}'\")\n",
    "\n",
    "    # â”€â”€ Compact fallback sample â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    sample_data = [\n",
    "        (\"tech\", \"Broadband speeds slow as demand for internet access rises across UK homes and offices rapidly.\"),\n",
    "        (\"tech\", \"Mobile phone sales hit record high as smartphone manufacturers compete for global market share.\"),\n",
    "        (\"tech\", \"Google launches new search algorithm update affecting millions of websites worldwide.\"),\n",
    "        (\"tech\", \"Apple unveils new MacBook laptop with faster processor and improved battery life for users.\"),\n",
    "        (\"tech\", \"Microsoft releases major Windows security patch to fix critical vulnerabilities found by researchers.\"),\n",
    "        (\"tech\", \"Amazon Web Services expands cloud computing data centres across Europe and Asia regions.\"),\n",
    "        (\"tech\", \"Artificial intelligence startup raises funding to develop natural language processing systems.\"),\n",
    "        (\"tech\", \"Cybersecurity firms warn of increasing ransomware attacks targeting hospitals and governments.\"),\n",
    "        (\"tech\", \"Electric vehicle software updates now delivered wirelessly over the air to Tesla cars.\"),\n",
    "        (\"tech\", \"Quantum computing breakthrough achieved by IBM scientists using new superconducting qubit design.\"),\n",
    "        (\"tech\", \"Netflix invests in faster content delivery networks to improve streaming quality globally.\"),\n",
    "        (\"tech\", \"Social media platforms face new regulations requiring faster removal of harmful content.\"),\n",
    "        (\"tech\", \"Robot warehouse workers deployed by logistics companies to meet growing e-commerce demand.\"),\n",
    "        (\"tech\", \"Chip shortage continues to disrupt global electronics supply chains affecting car manufacturers.\"),\n",
    "        (\"tech\", \"5G network rollout accelerates as telecoms operators compete for customers in urban areas.\"),\n",
    "        (\"tech\", \"Open source software community grows as developers contribute to collaborative coding projects.\"),\n",
    "        (\"tech\", \"Virtual reality headsets become more affordable opening gaming and education applications widely.\"),\n",
    "        (\"tech\", \"Data privacy laws require tech firms to store user information within national borders.\"),\n",
    "        (\"tech\", \"Autonomous drones tested for delivery services in rural areas with limited road infrastructure.\"),\n",
    "        (\"tech\", \"Wearable fitness trackers now monitor blood oxygen levels and detect irregular heartbeats.\"),\n",
    "        (\"business\", \"Oil prices rise sharply as OPEC nations agree to reduce production output globally.\"),\n",
    "        (\"business\", \"Retail sales fall for third consecutive month amid rising household energy bills.\"),\n",
    "        (\"business\", \"Bank of England raises interest rates again to combat persistent inflation in economy.\"),\n",
    "        (\"business\", \"Stock markets tumble as investors worry about slowing economic growth in China.\"),\n",
    "        (\"business\", \"Major supermarket chain reports record profits driven by higher food prices consumers pay.\"),\n",
    "        (\"business\", \"Unemployment rate drops to lowest level in decades as job vacancies remain high.\"),\n",
    "        (\"business\", \"Budget airline announces new routes and increased capacity heading into summer travel season.\"),\n",
    "        (\"business\", \"Housing market slows as rising mortgage rates make property less affordable for buyers.\"),\n",
    "        (\"business\", \"Global shipping costs decline as supply chain disruptions from pandemic ease gradually.\"),\n",
    "        (\"business\", \"Luxury goods sales boom as wealthy consumers increase spending on travel and fashion.\"),\n",
    "        (\"business\", \"Mergers and acquisitions activity surges as companies seek growth through strategic takeovers.\"),\n",
    "        (\"business\", \"Government announces new trade deal expected to boost exports and create manufacturing jobs.\"),\n",
    "        (\"business\", \"Pension funds increase investment in renewable energy infrastructure and green bonds.\"),\n",
    "        (\"business\", \"Start-up funding falls sharply as venture capital firms become more cautious about valuations.\"),\n",
    "        (\"business\", \"Consumer confidence index rises as inflation begins to ease and wages grow faster.\"),\n",
    "        (\"business\", \"Company CEO resigns amid shareholder pressure over falling profits and strategic direction.\"),\n",
    "        (\"business\", \"Foreign direct investment flows into emerging markets despite global economic uncertainty.\"),\n",
    "        (\"business\", \"Automotive industry invests billions in electric vehicle production lines across Europe.\"),\n",
    "        (\"business\", \"E-commerce sales continue to grow as consumers prefer shopping online over physical stores.\"),\n",
    "        (\"business\", \"Cryptocurrency market rebounds after months of decline attracting new retail investors.\"),\n",
    "        (\"sport\", \"England cricket team wins test series against Australia in thrilling final match.\"),\n",
    "        (\"sport\", \"Premier League title race intensifies with three clubs separated by just two points.\"),\n",
    "        (\"sport\", \"Olympic gold medallist announces retirement from professional athletics after successful career.\"),\n",
    "        (\"sport\", \"Tennis grand slam champion injured during training casting doubt over upcoming tournament.\"),\n",
    "        (\"sport\", \"Football transfer window closes with record spending by top clubs across Europe.\"),\n",
    "        (\"sport\", \"Rugby world cup host nation prepares stadiums and infrastructure for major tournament.\"),\n",
    "        (\"sport\", \"Formula One driver secures pole position with fastest qualifying lap of the season.\"),\n",
    "        (\"sport\", \"Cycling team disqualified after doping violations found during post-race urine tests.\"),\n",
    "        (\"sport\", \"Basketball star signs record breaking contract extension with NBA franchise for five years.\"),\n",
    "        (\"sport\", \"Swimming world record broken at championships by teenager making international debut.\"),\n",
    "        (\"sport\", \"Horse racing festival attracts record crowds and highest prize money in event history.\"),\n",
    "        (\"sport\", \"Golf major champion defends title with dominant final round performance at Augusta.\"),\n",
    "        (\"sport\", \"National football team qualifies for World Cup after dramatic playoff victory away.\"),\n",
    "        (\"sport\", \"Boxing champion retains title after unanimous points decision in Las Vegas bout.\"),\n",
    "        (\"sport\", \"Stadium expansion project approved bringing capacity to over sixty thousand fans.\"),\n",
    "        (\"sport\", \"Women's football league reports record attendances and television viewing figures this season.\"),\n",
    "        (\"sport\", \"Marathon world record broken in Berlin with runner finishing under two hour mark.\"),\n",
    "        (\"sport\", \"Cricket board announces new twenty-twenty competition to attract younger global audiences.\"),\n",
    "        (\"sport\", \"Winter Olympics preparations completed as host city finalises athlete village facilities.\"),\n",
    "        (\"sport\", \"Snooker world champion beats rival in longest final frame ever recorded at Sheffield.\"),\n",
    "        (\"entertainment\", \"Hollywood blockbuster breaks box office records earning one billion dollars in opening week.\"),\n",
    "        (\"entertainment\", \"Streaming platform announces new original series featuring award-winning director and cast.\"),\n",
    "        (\"entertainment\", \"Music artist releases surprise album gaining millions of streams within first twenty-four hours.\"),\n",
    "        (\"entertainment\", \"Film awards ceremony dominated by independent productions rather than major studio releases.\"),\n",
    "        (\"entertainment\", \"Video game sells five million copies in first week becoming fastest selling title ever.\"),\n",
    "        (\"entertainment\", \"Famous actor receives lifetime achievement award at international film festival ceremony.\"),\n",
    "        (\"entertainment\", \"Television drama series finale watched by record audience of twenty million viewers.\"),\n",
    "        (\"entertainment\", \"Pop star announces world tour dates following multi-year absence from live performances.\"),\n",
    "        (\"entertainment\", \"Animated film wins best picture award surprising industry experts and film critics.\"),\n",
    "        (\"entertainment\", \"Theatre production transfers to Broadway after successful run in London West End.\"),\n",
    "        (\"entertainment\", \"Celebrity couple announces separation after ten years of marriage in joint statement.\"),\n",
    "        (\"entertainment\", \"Book becomes bestseller weeks before film adaptation premieres in cinemas worldwide.\"),\n",
    "        (\"entertainment\", \"Comedy special filmed live becomes most watched stand-up show on streaming platform.\"),\n",
    "        (\"entertainment\", \"Music festival lineup revealed featuring headliners from rock pop and electronic genres.\"),\n",
    "        (\"entertainment\", \"Reality television show returns for new series with major format changes announced.\"),\n",
    "        (\"entertainment\", \"Podcast breaks download record becoming most listened programme in platform history.\"),\n",
    "        (\"entertainment\", \"Documentary about climate change wins award and sparks international policy debate.\"),\n",
    "        (\"entertainment\", \"Rapper collaborates with classical orchestra producing genre-defying album to critical acclaim.\"),\n",
    "        (\"entertainment\", \"Subscription costs rise at major streaming services causing viewer cancellations to increase.\"),\n",
    "        (\"entertainment\", \"Art exhibition draws record visitors after rare paintings go on display publicly.\"),\n",
    "        (\"politics\", \"Prime minister announces snap election amid falling poll ratings and party internal divisions.\"),\n",
    "        (\"politics\", \"Parliament debates new immigration bill as opposition parties demand significant amendments.\"),\n",
    "        (\"politics\", \"Foreign minister meets counterpart to discuss trade relations and diplomatic cooperation.\"),\n",
    "        (\"politics\", \"Government faces vote of no confidence after corruption allegations made against ministers.\"),\n",
    "        (\"politics\", \"United Nations security council votes on resolution addressing humanitarian crisis overseas.\"),\n",
    "        (\"politics\", \"Political party leadership contest begins after former leader resigns following election defeat.\"),\n",
    "        (\"politics\", \"New climate legislation passed requiring carbon emissions reductions by thirty percent.\"),\n",
    "        (\"politics\", \"Referendum results show narrow majority in favour of constitutional reform proposals.\"),\n",
    "        (\"politics\", \"Diplomatic tensions rise between neighbouring countries over disputed border territory.\"),\n",
    "        (\"politics\", \"Budget statement outlines tax increases and spending cuts to reduce government deficit.\"),\n",
    "        (\"politics\", \"Opposition leader criticises government handling of national health service funding crisis.\"),\n",
    "        (\"politics\", \"International sanctions imposed on country following violations of human rights agreements.\"),\n",
    "        (\"politics\", \"Local council elections produce surprise results shifting political balance in key regions.\"),\n",
    "        (\"politics\", \"President signs executive order addressing national security threats from foreign actors.\"),\n",
    "        (\"politics\", \"Peace talks begin between rival factions with international mediators facilitating negotiations.\"),\n",
    "        (\"politics\", \"Whistleblower reveals confidential government documents causing major political scandal.\"),\n",
    "        (\"politics\", \"Election commission investigates alleged campaign finance violations by major party.\"),\n",
    "        (\"politics\", \"New transport infrastructure bill promises investment in roads railways and digital networks.\"),\n",
    "        (\"politics\", \"Protests erupt in capital city as citizens demonstrate against proposed austerity measures.\"),\n",
    "        (\"politics\", \"Coalition government collapses as junior partner withdraws support over policy disagreement.\"),\n",
    "    ]\n",
    "    df = pd.DataFrame(sample_data, columns=[\"category\", \"text\"])\n",
    "    print(f\"âœ… Fallback sample loaded: {len(df)} articles, {df['category'].nunique()} categories.\")\n",
    "\n",
    "# Reset index so iloc lookups are consistent\n",
    "df = df.reset_index(drop=True)\n",
    "print(f\"\\nFinal dataset shape : {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Text preprocessing\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Simple stopword list (avoiding NLTK download requirement)\n",
    "STOPWORDS = set([\n",
    "    \"a\",\"an\",\"the\",\"and\",\"or\",\"but\",\"in\",\"on\",\"at\",\"to\",\"for\",\"of\",\"with\",\n",
    "    \"by\",\"from\",\"as\",\"is\",\"was\",\"are\",\"were\",\"be\",\"been\",\"being\",\"have\",\n",
    "    \"has\",\"had\",\"do\",\"does\",\"did\",\"will\",\"would\",\"could\",\"should\",\"may\",\n",
    "    \"might\",\"shall\",\"can\",\"it\",\"its\",\"this\",\"that\",\"these\",\"those\",\"i\",\n",
    "    \"he\",\"she\",\"we\",\"they\",\"you\",\"me\",\"him\",\"her\",\"us\",\"them\",\"my\",\"his\",\n",
    "    \"their\",\"our\",\"your\",\"not\",\"no\",\"nor\",\"so\",\"yet\",\"both\",\"either\",\n",
    "    \"each\",\"few\",\"more\",\"most\",\"other\",\"some\",\"such\",\"than\",\"too\",\"very\",\n",
    "    \"just\",\"also\",\"about\",\"after\",\"before\",\"between\",\"into\",\"through\",\n",
    "    \"during\",\"over\",\"up\",\"down\",\"out\",\"off\",\"then\",\"once\",\"here\",\"there\",\n",
    "    \"when\",\"where\",\"how\",\"all\",\"any\",\"new\",\"said\",\"say\",\"says\"\n",
    "])\n",
    "\n",
    "def preprocess(text):\n",
    "    \"\"\"Lowercase â†’ remove punctuation â†’ tokenize â†’ remove stopwords.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    tokens = text.split()\n",
    "    tokens = [t for t in tokens if t not in STOPWORDS and len(t) > 2]\n",
    "    return tokens\n",
    "\n",
    "df[\"tokens\"] = df[\"text\"].apply(preprocess)\n",
    "\n",
    "print(\"Sample preprocessing:\")\n",
    "print(f\"  Original : {df['text'][0]}\")\n",
    "print(f\"  Tokens   : {df['tokens'][0]}\")\n",
    "print(f\"  Count    : {len(df['tokens'][0])} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_emb",
   "metadata": {},
   "source": [
    "## ğŸ§  Module 2: Word2Vec Embedding Generation\n",
    "We train a **Word2Vec Skip-Gram** model from scratch on the BBC corpus, then produce sentence-level vectors by **mean-pooling** word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train Word2Vec model on the BBC corpus\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = df[\"tokens\"].tolist()  # list of token lists\n",
    "\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    vector_size=100,    # embedding dimensions\n",
    "    window=5,           # context window size\n",
    "    min_count=1,        # include all words\n",
    "    sg=1,               # 1 = Skip-Gram, 0 = CBOW\n",
    "    epochs=100,         # training epochs\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"âœ… Word2Vec trained successfully!\")\n",
    "print(f\"   Vocabulary size : {len(w2v_model.wv.key_to_index)} words\")\n",
    "print(f\"   Vector size     : {w2v_model.vector_size} dimensions\")\n",
    "print(f\"   Training mode   : Skip-Gram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Explore learned word vectors\n",
    "import numpy as np\n",
    "\n",
    "# Most similar words for selected seed words\n",
    "seed_words = [\"technology\", \"football\", \"government\", \"market\", \"film\"]\n",
    "\n",
    "for word in seed_words:\n",
    "    if word in w2v_model.wv:\n",
    "        similar = w2v_model.wv.most_similar(word, topn=4)\n",
    "        pairs = \", \".join([f\"{w} ({s:.2f})\" for w, s in similar])\n",
    "        print(f\"  '{word}' â†’ {pairs}\")\n",
    "    else:\n",
    "        print(f\"  '{word}' not in vocabulary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Generate sentence vectors via mean-pooling of word vectors\n",
    "def sentence_vector(tokens, model):\n",
    "    \"\"\"Average the Word2Vec vectors of all known tokens in a sentence.\"\"\"\n",
    "    vecs = [model.wv[t] for t in tokens if t in model.wv]\n",
    "    if not vecs:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(vecs, axis=0)\n",
    "\n",
    "# Build sentence embedding matrix  shape: (N x 100)\n",
    "sentence_vectors = np.array([sentence_vector(tok, w2v_model) for tok in df[\"tokens\"]])\n",
    "print(f\"Sentence embedding matrix shape : {sentence_vectors.shape}\")\n",
    "print(f\"Sample vector (first 8 dims)    : {sentence_vectors[0][:8].round(4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_search",
   "metadata": {},
   "source": [
    "## ğŸ” Module 3A: Semantic Search\n",
    "Given a **query sentence**, encode it with the same Word2Vec pipeline and rank all articles by **cosine similarity**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Cosine similarity helper\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def semantic_search(query, df, sentence_vectors, w2v_model, top_n=5):\n",
    "    \"\"\"\n",
    "    Encode query â†’ compute cosine similarity vs all articles\n",
    "    â†’ return top-N results with similarity scores.\n",
    "    \"\"\"\n",
    "    query_tokens = preprocess(query)\n",
    "    query_vec    = sentence_vector(query_tokens, w2v_model).reshape(1, -1)\n",
    "\n",
    "    sims = cosine_similarity(query_vec, sentence_vectors)[0]\n",
    "\n",
    "    top_indices = sims.argsort()[::-1][:top_n]\n",
    "    results = []\n",
    "    for rank, idx in enumerate(top_indices, 1):\n",
    "        results.append({\n",
    "            \"Rank\"      : rank,\n",
    "            \"Score\"     : round(float(sims[idx]), 4),\n",
    "            \"Category\"  : df[\"category\"].iloc[idx],\n",
    "            \"Article\"   : df[\"text\"].iloc[idx]\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# â”€â”€ Run three example queries â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "queries = [\n",
    "    \"smartphone internet mobile technology\",\n",
    "    \"football match premier league\",\n",
    "    \"economy inflation interest rates\"\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    print(f\"\\n{'â”€'*65}\")\n",
    "    print(f\"ğŸ” Query: '{q}'\")\n",
    "    print(f\"{'â”€'*65}\")\n",
    "    results = semantic_search(q, df, sentence_vectors, w2v_model, top_n=3)\n",
    "    for _, row in results.iterrows():\n",
    "        print(f\"  #{row['Rank']} [{row['Category'].upper()}] (score={row['Score']})\")\n",
    "        print(f\"     {row['Article']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_rec",
   "metadata": {},
   "source": [
    "## ğŸ¯ Module 3B: Recommendation System\n",
    "Given an **article index**, find the most similar articles across the corpus â€” article-to-article recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Article-to-article recommendation\n",
    "def recommend(article_idx, df, sentence_vectors, top_n=5):\n",
    "    \"\"\"\n",
    "    Given an article index, return top-N most similar articles\n",
    "    (excluding the article itself).\n",
    "    \"\"\"\n",
    "    query_vec = sentence_vectors[article_idx].reshape(1, -1)\n",
    "    sims      = cosine_similarity(query_vec, sentence_vectors)[0]\n",
    "\n",
    "    # Exclude the article itself\n",
    "    sims[article_idx] = -1\n",
    "    top_indices = sims.argsort()[::-1][:top_n]\n",
    "\n",
    "    results = []\n",
    "    for rank, idx in enumerate(top_indices, 1):\n",
    "        results.append({\n",
    "            \"Rank\"     : rank,\n",
    "            \"Score\"    : round(float(sims[idx]), 4),\n",
    "            \"Category\" : df[\"category\"].iloc[idx],\n",
    "            \"Article\"  : df[\"text\"].iloc[idx]\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# â”€â”€ Demonstrate on 3 seed articles â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "seed_articles = [0, 20, 40]   # tech, business, sport\n",
    "\n",
    "for seed in seed_articles:\n",
    "    print(f\"\\n{'â•'*65}\")\n",
    "    print(f\"ğŸ“° SEED ARTICLE [{df['category'].iloc[seed].upper()}]\")\n",
    "    print(f\"   {df['text'].iloc[seed]}\")\n",
    "    print(f\"{'â”€'*65}\")\n",
    "    print(\"   ğŸ“Œ TOP RECOMMENDATIONS:\")\n",
    "    recs = recommend(seed, df, sentence_vectors, top_n=4)\n",
    "    for _, row in recs.iterrows():\n",
    "        print(f\"   #{row['Rank']} [{row['Category'].upper()}] (score={row['Score']})\")\n",
    "        print(f\"      {row['Article']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_viz",
   "metadata": {},
   "source": [
    "## ğŸ“Š Module 4: Visualization\n",
    "We project 100-dimensional sentence vectors down to 2D using **PCA** and **t-SNE** to visually inspect clustering by news category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: PCA visualization (2D)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "CATEGORY_COLORS = {\n",
    "    \"tech\"          : \"#4E79A7\",\n",
    "    \"business\"      : \"#F28E2B\",\n",
    "    \"sport\"         : \"#59A14F\",\n",
    "    \"entertainment\" : \"#E15759\",\n",
    "    \"politics\"      : \"#B07AA1\"\n",
    "}\n",
    "\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "pca_coords = pca.fit_transform(sentence_vectors)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "for cat, color in CATEGORY_COLORS.items():\n",
    "    mask = df[\"category\"] == cat\n",
    "    ax.scatter(\n",
    "        pca_coords[mask, 0], pca_coords[mask, 1],\n",
    "        c=color, label=cat.capitalize(), alpha=0.85,\n",
    "        edgecolors=\"white\", linewidths=0.6, s=80\n",
    "    )\n",
    "\n",
    "ax.set_title(\"PCA â€” BBC News Articles by Category (Word2Vec Embeddings)\",\n",
    "             fontsize=14, fontweight=\"bold\", pad=12)\n",
    "ax.set_xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)\")\n",
    "ax.set_ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)\")\n",
    "ax.legend(title=\"Category\", framealpha=0.9)\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"pca_visualization.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(f\"PCA explains {sum(pca.explained_variance_ratio_)*100:.1f}% of total variance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: t-SNE visualization (2D) â€” better non-linear cluster separation\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Perplexity must be < number of samples\n",
    "perplexity = min(30, len(df) - 1)\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42,\n",
    "            n_iter=1000, learning_rate=\"auto\", init=\"pca\")\n",
    "tsne_coords = tsne.fit_transform(sentence_vectors)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "for cat, color in CATEGORY_COLORS.items():\n",
    "    mask = df[\"category\"] == cat\n",
    "    ax.scatter(\n",
    "        tsne_coords[mask, 0], tsne_coords[mask, 1],\n",
    "        c=color, label=cat.capitalize(), alpha=0.85,\n",
    "        edgecolors=\"white\", linewidths=0.6, s=80\n",
    "    )\n",
    "\n",
    "ax.set_title(\"t-SNE â€” BBC News Articles by Category (Word2Vec Embeddings)\",\n",
    "             fontsize=14, fontweight=\"bold\", pad=12)\n",
    "ax.set_xlabel(\"t-SNE Dimension 1\")\n",
    "ax.set_ylabel(\"t-SNE Dimension 2\")\n",
    "ax.legend(title=\"Category\", framealpha=0.9)\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"tsne_visualization.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"t-SNE visualization saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Cosine similarity heatmap â€” 20 sample articles\n",
    "import seaborn as sns\n",
    "\n",
    "# Pick 4 from each category for a balanced heatmap\n",
    "sample_idx = []\n",
    "for cat in [\"tech\", \"business\", \"sport\", \"entertainment\", \"politics\"]:\n",
    "    idxs = df[df[\"category\"] == cat].index.tolist()[:4]\n",
    "    sample_idx.extend(idxs)\n",
    "\n",
    "sample_vecs   = sentence_vectors[sample_idx]\n",
    "sim_matrix    = cosine_similarity(sample_vecs)\n",
    "sample_labels = [f\"{df['category'].iloc[i][:3].upper()}-{i}\" for i in sample_idx]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    sim_matrix,\n",
    "    xticklabels=sample_labels, yticklabels=sample_labels,\n",
    "    cmap=\"RdYlGn\", vmin=0, vmax=1, annot=True, fmt=\".2f\",\n",
    "    linewidths=0.5, linecolor=\"white\", annot_kws={\"size\": 7},\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title(\"Cosine Similarity Heatmap â€” 20 Sample Articles\",\n",
    "             fontsize=14, fontweight=\"bold\", pad=12)\n",
    "plt.xticks(rotation=45, ha=\"right\", fontsize=8)\n",
    "plt.yticks(rotation=0, fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"similarity_heatmap.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Cosine similarity heatmap saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Word vector similarity â€” top-10 similar words for key terms\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "probe_words = [\"election\", \"cricket\", \"software\"]\n",
    "\n",
    "for ax, word in zip(axes, probe_words):\n",
    "    if word not in w2v_model.wv:\n",
    "        ax.set_title(f\"'{word}' not in vocab\")\n",
    "        continue\n",
    "    similar = w2v_model.wv.most_similar(word, topn=10)\n",
    "    words, scores = zip(*similar)\n",
    "    colors = plt.cm.Blues(np.linspace(0.4, 0.9, len(words)))\n",
    "    ax.barh(list(words)[::-1], list(scores)[::-1], color=colors[::-1])\n",
    "    ax.set_xlabel(\"Cosine Similarity\")\n",
    "    ax.set_title(f\"Words similar to '{word}'\", fontweight=\"bold\")\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.grid(axis=\"x\", linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "plt.suptitle(\"Top-10 Similar Words (Word2Vec)\", fontsize=14, fontweight=\"bold\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"word_similarity_bars.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12: Evaluation â€” Intra vs Inter category similarity\n",
    "categories = df[\"category\"].unique()\n",
    "\n",
    "intra_sims = {}  # avg similarity WITHIN a category\n",
    "inter_sims = {}  # avg similarity ACROSS different categories\n",
    "\n",
    "for cat in categories:\n",
    "    cat_idx   = df[df[\"category\"] == cat].index.tolist()\n",
    "    other_idx = df[df[\"category\"] != cat].index.tolist()\n",
    "\n",
    "    cat_vecs   = sentence_vectors[cat_idx]\n",
    "    other_vecs = sentence_vectors[other_idx]\n",
    "\n",
    "    if len(cat_idx) > 1:\n",
    "        sim_intra = cosine_similarity(cat_vecs)\n",
    "        np.fill_diagonal(sim_intra, 0)\n",
    "        intra_sims[cat] = sim_intra.sum() / (len(cat_idx) * (len(cat_idx) - 1))\n",
    "    \n",
    "    inter_sims[cat] = cosine_similarity(cat_vecs, other_vecs).mean()\n",
    "\n",
    "print(\"Category Embedding Quality (higher intra & lower inter = better clusters)\")\n",
    "print(f\"{'Category':<15} {'Intra-sim':>12} {'Inter-sim':>12} {'Separation':>12}\")\n",
    "print(\"â”€\" * 55)\n",
    "for cat in categories:\n",
    "    intra = intra_sims.get(cat, 0)\n",
    "    inter = inter_sims.get(cat, 0)\n",
    "    sep   = intra - inter\n",
    "    print(f\"{cat:<15} {intra:>12.4f} {inter:>12.4f} {sep:>12.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13: Pipeline Summary\n",
    "print(\"=\" * 60)\n",
    "print(\"     SEMANTIC SEARCH & RECOMMENDATION SYSTEM â€” SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Dataset         : BBC News (English)\")\n",
    "print(f\"  Articles        : {len(df)} ({df['category'].nunique()} categories)\")\n",
    "print(f\"  Preprocessing   : Lowercase + Punct removal + Stopword filter\")\n",
    "print(f\"  Embedding Model : Word2Vec Skip-Gram (trained from scratch)\")\n",
    "print(f\"  Vocabulary      : {len(w2v_model.wv.key_to_index)} unique tokens\")\n",
    "print(f\"  Vector Size     : {w2v_model.vector_size} dimensions\")\n",
    "print(f\"  Sentence Vecs   : Mean pooling of word vectors\")\n",
    "print(f\"  Search Method   : Cosine Similarity ranking\")\n",
    "print(f\"  Visualization   : PCA + t-SNE + Cosine Heatmap + Word Bars\")\n",
    "print(\"=\" * 60)\n",
    "print(\"  âœ… Semantic Search  â€” working\")\n",
    "print(\"  âœ… Recommendation   â€” working\")\n",
    "print(\"  âœ… PCA visualization â€” saved\")\n",
    "print(\"  âœ… t-SNE visualization â€” saved\")\n",
    "print(\"  âœ… Similarity heatmap  â€” saved\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
